---
title: My Bachelor's Degree Thesis
draft: false
tags:
  - projects
---
 In 2024 I finished my Bachelor's studies at Technical University of Cluj-Napoca. My diploma project is intitulated [[Visual-Inertial Odometry based on lane-detection of an autonomous vehicle with constant speed]].

### Motivation
* I chose this project because of [Steven Gong](https://stevengong.co/) and his experience at F1Tenth; an autonomous racing contest for 1:10 RC Cars. 
* Another inspiration for this project was also [SPOT](https://bostondynamics.com/products/spot/) by Boston Dynamics. The main attraction was the Real-Time SLAM algorithm it could execute.

### Introduction

>[!NOTE] What is sensor fusion and odometry?
>	[[Sensor fusion]] is collecting and integrating data from multiple sensors in order to get a better understanding of the process that we're monitoring than if it came from a single source.
>	
>	[[Odometry]] is transforming data coming from sensors that give movement or displacement in order to estimate the [[ego's]] change in position over time.

<div class="container" style="display: flex; justify-content: center; align-items: center;">
    <img src="../static/orientation.png" style="max-width: 100%; height: auto;">
</div>

> [!question] Why constant speed?
> "The linear acceleration signal typically cannot be integrated to recover velocity, or double-integrated to recover position. The error typically becomes larger than the signal within less than 1 second if other sensor sources are not used to compensate this integration error." - [[BNO055]] documentation
> $$
> noise = 1[mg] = 0.001[g] = 0.001 \times 9.81[m/s^{2}] = 0.00981 [m/s^{2}],
> $$
> $$
> displacement = \frac{1}{2} \times a \times \textbf{t}^{2},
> $$
> $$
> \frac{1}{2} \times a \times t^{2} \approx 49[m], \text{ where } \textbf{t} = 100[seconds].
> $$
> This right here shows that for 100 [seconds] and a 1 [mg] constant of noise there are 49 [meters] of false displacement. My setup did not allow me to add different movement sensors and so I considered constant speed because the [[BLDC Motor]] was in a close loop with the [[ESC]], assuring a [[Adaptive Cruise Control]] behaviour.
 
I will further touch on the connections between the components that I used:

<div class="container" style="display: flex; justify-content: center; align-items: center;">
    <img src="../static/connDiag.png" style="max-width: 100%; height: auto;">
</div>
Here, the NUCLEO took care of the real-time algorithms:

* control of the servomotor and the BLDC Motor,
* [[inertial-odom|Inertial Odometry]]
* [[Kalman Filter]],

and the Raspberry Pi 4B executed all of the perception algorithms:
* Lane-Detection
* [[visual-odom|Visual Odometry]]

### Control of the servomotor in closed-loop
The main goal of this was to position the ego on the middle of the lane. As error; it would always get the lateral error in [cm] to the middle line generated by the lane-detection algorithm. The proposed control loop was [[Proportional-Derivative]] as it gave the best results when testing.

### Kinematic Model
In order to get displacement; I needed a [[Kinematic Model]]. It was very simplified; as in decomposing the speed vector in the X and Y axis by using the cosinus and sinus trigonometrical functions. The [[Yaw]] was updated through a common technique found in the [[Bicycle Kinematic Model]]. I can use these formulas because of the constant speed.
$$
\Delta{x} = v \cdot t \cdot \cos(\psi),
$$
$$
\Delta{y} = v \cdot t \cdot \sin(\psi),
$$
$$
const = \frac{360 \cdot \Delta{t}}{2 \cdot \pi \cdot L}
$$
$$
\psi = \psi + const \cdot \tan(\theta)
$$
### Kalman Filter

>[!NOTE] It performs the fusion of the two sensors, resulting in visual-inertial odometry
>Since the [[Kalman Filter]] considers linear processes and this process is clearly nonlinear (trigonometric functions), I can say that I have performed a point-by-point linearization so that the value is considered constant for the entire duration of 100 [ms].

